- liste de requêtes prédéfinies (exemple sur date de création de fichier en cohérence avec le SVN : alors range "gte": "01/01/2016")
cela permettrait de récupérer tous les derniers fichiers modifiés sur le SVN

- Corrections sur l'affichage des fragments d'aperçus de fichiers et mise en forme
- fonctions d'échappement des caractères html angularjs "escapeall" (seulement pour le cas des findAll durant lequel le contenu est renvoyé brut,
et ce n'est pas un highlight formatté par elasticsearch et le mode highlight encode html)

## Mettre les filtres en exclusions
exemple, par un ctrl+clic sur un filtre de version, afficher en rouge la version exclue, et lancer la recherche sur toutes les versions sauf celles exclues
ou alors, par un bouton switch on/off si le filtre agit en inclusion/exclusion

SVN :
utilisation du paramètre : -Dsvnkit.http.spoolDirectory=./spooldirectory
permet de réaliser un checkout temporaire et éviter les soucis de E175002: REPORT request failed on '/svn/!svn/vcc/default'


*********** page d'aide ************
les wildcards et joker (* / ?)
les champs à utiliser lastDate, lastAuthor, name, path, version, project, size
les dates :
    lastDate:<2010-01-01 AND lastDate:>2005-01-01
    ou mieux
    lastDate:[2012-01-01 2016-01-01]
    en filtrant avec l'heure précise : lastDate:[2016-01-01T00:00:00 2016-01-04T10:00:00]
mais encore :
lastDate:[now-12h now]
lastDate:[now-12h *]
************************************


1)fonctionnalitée à inclure
- inclure un moteur de recherche intégré à la page qui s'enregistre dans le navigateur, avec un raccourci clavier (k ?)
- le crate https://docs.rs/croner/latest/croner/ a l'air mieux que cron

2)filtre sur date de modif

## Crawler
 - dans le crawler, si le last_modified n'a pas bougé, alors on ne réindexe pas le fichier en question
 - pouvoir parcourir dans le crawler directement le SVN / Git (voir point 1)
 - gérer l'accès en JWT à l'api crawler (utiliser le user system ?) voir : https://github.com/Gleetr/auth0-curl/blob/master/curl-auth0

####IDEE A PENSER####
Faire des filtres directement sur les entêtes des colonnes (on pourrait par exemple imaginer que "extension" a un filtre "java" et version a un filtre "branche1"
cela permettra d'éviter d'écrire directement dans le champ de recherche pour les non initiés des requêtes du genre "version:branche1 AND extension:java"


- quand, on réindex un document existant, comment on fait, date, est-ce qu'il est bien supprimé d'une version etc, ou tout court ?
- enregistrer le document une seule fois dans l'index, et enregistrer une liste des versions, des paths, des projets, si le contenu est le même ?

Gros problème : si un crawl immense n'était pas fini et que le serveur redémarre, le serveur reprend le crawling au démarrage, mais il ne répond à aucune autre requêtes => IMPOSSIBLE de se logguer !
